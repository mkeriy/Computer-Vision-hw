{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd80301",
   "metadata": {},
   "source": [
    "Все ДЗ состоит из двух частей. Первая часть более развернутая и экспериментальная - в ней вам нужно будет обучить архитектуру для задачи Image Classification. Вам нужно реализовать архитектуру, обучить ее, а так же выполнить некоторые дополнительные задания. Вторая часть более простая - вам просто требуется разобраться во фреймворке и запустить его на данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cea900b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libs\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd98fa2",
   "metadata": {},
   "source": [
    "# ДЗ 2.1 Image classification. 16 баллов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b40a0d",
   "metadata": {},
   "source": [
    "В качестве датасета будет использовать вот этот - https://www.kaggle.com/datasets/slothkong/10-monkey-species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a6ca6",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09644a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd827c83",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cd79c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6b4931",
   "metadata": {},
   "source": [
    "## ResNet50."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509a28f",
   "metadata": {},
   "source": [
    "Реализуйте ResNet50. Чтобы вспомнить архитектуру, обратитесь к лекции + оригинальной статье авторов+google.\n",
    "\n",
    "Если хотите реализовать что-то поинтереснее (ViT) - делайте, будет учтено."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4097d4",
   "metadata": {},
   "source": [
    "Что будет оцениваться в задании:\n",
    "* ResNet50 from scratch **6 баллов**\n",
    "* добавьте аугментаций, напишите краткое саммари почему выбрали именно такой набор аугментаций. **1 балл**\n",
    "* дописать логику обучения модели **2 балла**\n",
    "* дописать логику тестирования модели **1 балл**\n",
    "* возьмите еще 2 модели из зоопарка моделей [torchvision](https://pytorch.org/vision/stable/models.html?), зафайнтюньте на наш датасет. Сравните их между собой и вашей реализацией. **4 балла**\n",
    "* обязательно в конце напишите общий отчет о проделанной работе. Для лучшей модели проведите анализ метрик и ошибок, постройте confusion_matrix и classification report **2 балла**\n",
    "* графики обучения обязательно должны присутсвовать\n",
    "\n",
    "**NOTE**: рядом лежит ноутбук с baseline solution, вы можете отталкиваться от него, если хотите."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3586851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_3x3(in_channels, out_channels, stride=1, dilation=1, groups=1):\n",
    "    return nn.Conv2d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=dilation,\n",
    "        dilation=dilation,\n",
    "        groups=groups,\n",
    "        bias=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_1x1(in_channels, out_channels, stride=1):\n",
    "    return nn.Conv2d(\n",
    "        in_channels, out_channels, kernel_size=1, stride=stride, bias=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7227a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleNeck(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_channels, channels, stride=1, groups=1, dilation=1, downsample=None\n",
    "    ):\n",
    "        super(BottleNeck, self).__init__()\n",
    "        norm_layer = nn.BatchNorm2d\n",
    "        width = int(channels * groups)\n",
    "\n",
    "        self.conv1 = conv_1x1(in_channels, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv_3x3(\n",
    "            width, width, stride=stride, groups=groups, dilation=dilation\n",
    "        )\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv_1x1(width, channels * 4)\n",
    "        self.bn3 = norm_layer(channels * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connection = x\n",
    "        if self.downsample is not None:\n",
    "            skip_connection = self.downsample(x)\n",
    "\n",
    "        output = self.conv1(x)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.bn2(output)\n",
    "        output = self.relu(output)\n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output += skip_connection\n",
    "        output = nn.relu(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac22004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=3)\n",
    "\n",
    "        self.layer_1 = self._build_layer(channels=64, num_blocks=3)\n",
    "        self.layer_2 = self._build_layer(channels=128, num_blocks=4, stride=2)\n",
    "        self.layer_3 = self._build_layer(channels=256, num_blocks=6, stride=2)\n",
    "        self.layer_4 = self._build_layer(channels=512, num_blocks=3, stride=2)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    module.weight, mode=\"fan_out\", nonlinearity=\"relu\"\n",
    "                )\n",
    "            elif isinstance(module, nn.BatchNorm2d):\n",
    "                nn.init.constant_(module.weight, 1)\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.max_pool(out)\n",
    "\n",
    "        out = self.layer_1(out)\n",
    "        out = self.layer_2(out)\n",
    "        out = self.layer_3(out)\n",
    "        out = self.layer_4(out)\n",
    "\n",
    "        out = self.avg_pool(out)\n",
    "        out = torch.flatten(x, 1)\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def _build_layer(self, channels, num_blocks, stride=1):\n",
    "\n",
    "        downsample = nn.Sequential(\n",
    "            conv_1x1(self.in_channels, channels * 4, stride),\n",
    "            nn.BatchNorm2d(channels * 4),\n",
    "        )\n",
    "        blocks = []\n",
    "        blocks.append(\n",
    "            BottleNeck(self.in_channels, channels, stride=stride, downsample=downsample)\n",
    "        )\n",
    "        self.in_channels = channels * 4\n",
    "        for _ in range(1, num_blocks):\n",
    "            blocks.append(BottleNeck(self.in_channels, channels, stride=stride))\n",
    "\n",
    "        return nn.Sequential(*blocks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa3ed5",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f81fd00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9848432e",
   "metadata": {},
   "source": [
    "# Test and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc181ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f33a7a3",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb6d89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7deea1bf",
   "metadata": {},
   "source": [
    "# ДЗ 2.2. Object detection. 8 баллов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca7bcf",
   "metadata": {},
   "source": [
    "Здесь я прошу вас воспользоваться популярным фреймворком для задачи object detection - YOLOv8. Но, если хотите, можете поиграться с моделями из mmdetection например, или запустить детекцию на DETR. Тоже будет оценено. YOLOv8 выбран как самый простой и удобный вариант. Ссылка на гитхаб и документацию - https://github.com/ultralytics/ultralytics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcaba02",
   "metadata": {},
   "source": [
    "Вам требуется поставить фреймворк, обучить модель детекции на данных, вывести графики лоссов и метрики на тестовом датасете. Покажите предсказания модели на 10 примерах из тестового набора данных. В этом задании не будет оцениваться каждый пункт по отдельности, а только вся проведенная работа в целом."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fee31e4",
   "metadata": {},
   "source": [
    "Обучать лучше на GPU, но на CPU тоже возможно. Маленькая версия YOLO с ресайзом до 320 у меня обучалась около 40 минут на CPU. Данные нужно скачать отсюда - https://public.roboflow.com/object-detection/oxford-pets/1/download/yolov8 (скачайте в формате YOLO). Имейте ввиду, что вам скорее всего нужно будет поменять пути в `data.yaml`, поставив абсолютные пути до папок. Например:\n",
    "\n",
    "`train: /Users/mark/Desktop/Update820/train` и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fff0ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
